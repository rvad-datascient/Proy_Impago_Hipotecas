
# ğŸ  PredicciÃ³n de Impagos Hipotecarios con Machine Learning

Este proyecto utiliza tÃ©cnicas avanzadas de Machine Learning para predecir la probabilidad de que un cliente incurra en impagos hipotecarios.

Aunque se trata de un caso simulado, los datos provienen del conjunto **"Give Me Some Credit"** publicado en Kaggle, ampliamente utilizado para problemas de scoring crediticio.  
El proyecto abarca desde el anÃ¡lisis exploratorio hasta el despliegue de una app funcional mediante Streamlit.

---
## ğŸ“Œ Objetivo

Desarrollar un modelo predictivo que permita a entidades financieras **anticipar impagos** en solicitudes de crÃ©ditos hipotecarios, ayudando asÃ­ en la gestiÃ³n de riesgo y toma de decisiones.

---
## ğŸ§° TecnologÃ­as utilizadas

- Python
- Scikit-learn
- XGBoost, LightGBM, CatBoost
- Optuna
- SMOTE
- Streamlit
- SHAP

## ğŸ“ Estructura del proyecto
```
Proy_Impago_Hipotecas/
â”œâ”€â”€ 03_notebooks/                          # Notebooks de anÃ¡lisis y transformaciÃ³n
â”‚   â”œâ”€â”€ Env_0_Datos_+_EDA_...ipynb         # ExploraciÃ³n y EDA del dataset
â”‚   â””â”€â”€ Env_1_Limpieza_Datos_...ipynb      # Feature engineering y limpieza
â”‚
â”œâ”€â”€ 05_ml_project/                         # App en producciÃ³n y componentes
â”‚   â”œâ”€â”€ app.py                             # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ limpieza_basica.py                 # Clase para limpieza avanzada
â”‚   â”œâ”€â”€ preprocesamiento.py                # Funciones de transformaciÃ³n y escalado
â”‚   â”œâ”€â”€ modelo_voting_fixed.pkl            # Modelo VotingClassifier entrenado
â”‚   â”œâ”€â”€ scaler_robust.pkl                  # Escalador robusto para inputs
â”‚   â””â”€â”€ requirements.txt                   # LibrerÃ­as necesarias para producciÃ³n
â”‚
â”œâ”€â”€ .gitignore                             # ExclusiÃ³n de archivos/carpetas innecesarias
â””â”€â”€ README.md                              # DescripciÃ³n del proyecto
```
## ğŸ§ª Modelos probados

Se evaluaron varios modelos de boosting:

- âœ… **CatBoost** (mejor equilibrio entre recall y precisiÃ³n)
- âœ… **XGBoost** (mayor recall sin umbral ajustado)
- âœ… **LightGBM** (buena velocidad y rendimiento)
- âœ… **VotingClassifier** (mejor resultado combinado)

### ğŸ” Mejor combinaciÃ³n (Voting XGB + CatBoost):
- Precision: 0.36
- Recall: 0.51
- F1-score: 0.42
- ROC AUC: 0.86

---

## ğŸš€ Ver la App


```bash
streamlit run app.py
```

La app se abrirÃ¡ automÃ¡ticamente en tu navegador.

---

## ğŸ“Š Dataset

- **Fuente**: Kaggle - [Give Me Some Credit Dataset](https://www.kaggle.com/c/GiveMeSomeCredit)
- **Observaciones**: 150.000 clientes con informaciÃ³n financiera
- **Variable objetivo**: Impago2AÃ±os Nombre original:`SeriousDlqin2yrs` â†’ indica si el cliente tuvo impagos en los prÃ³ximos 2 aÃ±os

---

## ğŸ§  Â¿QuÃ© incluye este proyecto?

- Limpieza avanzada de datos con clase personalizada (`LimpiezaBasica`)
- Preprocesamiento: winsorizaciÃ³n + escalado robusto + SMOTE
- ComparaciÃ³n de modelos Boosting y VotingClassifier
- OptimizaciÃ³n de hiperparÃ¡metros con Optuna
- Ajuste del umbral de decisiÃ³n
- AplicaciÃ³n de predicciÃ³n con Streamlit

---
## ğŸ’¡ Sobre MÃ­

ğŸ‘‹ Â¡Hola! Soy Raquel, profesional en transiciÃ³n hacia la Ciencia de Datos, con experiencia previa en anÃ¡lisis financiero y mejora de procesos. Me apasiona transformar datos en decisiones Ãºtiles y aplicar modelos predictivos para resolver problemas reales.

ğŸ“Š Este proyecto es parte de mi portfolio y representa un caso completo de predicciÃ³n de impagos hipotecarios. Incluye anÃ¡lisis exploratorio, limpieza de datos, entrenamiento de modelos con tÃ©cnicas avanzadas (XGBoost, CatBoost, VotingClassifier), y despliegue de una app interactiva usando Streamlit.

ğŸš€ Actualmente sigo profundizando en temas como interpretabilidad con SHAP, balanceo de clases con SMOTE, y desarrollo de soluciones de datos listas para producciÃ³n.
